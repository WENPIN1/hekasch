use chrono::Local;
use regex::Regex;
use scraper::{Html, Selector};
use std::collections::HashMap;
use std::error::Error;
use std::time::Duration;
use tokio::time::sleep;

use stock_crawler::company_info::{load_stock_database, save_stock_database, StockInfo};

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    env_logger::init();
    
    let input_file = "stock_infos_2026-01-27.json";
    let output_file = "stock_infos_with_websites_2026-01-27.json";
    
    println!("ğŸ“– è®€å–è‚¡ç¥¨è³‡æ–™åº«...");
    let mut database = load_stock_database(input_file)?;
    
    let total = database.len();
    let needs_update_count = database.values().filter(|s| s.website.is_none()).count();
    
    println!("âœ… è¼‰å…¥ {} å®¶å…¬å¸è³‡æ–™", total);
    println!("ğŸ”„ éœ€è¦æ›´æ–°: {} å®¶", needs_update_count);
    
    if needs_update_count == 0 {
        println!("âœ¨ æ‰€æœ‰å…¬å¸éƒ½å·²æœ‰å®˜ç¶²è³‡æ–™!");
        return Ok(());
    }
    
    let client = reqwest::Client::builder()
        .user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        .timeout(Duration::from_secs(30))
        .build()?;
    
    let mut processed = 0;
    let codes: Vec<String> = database.keys().cloned().collect();
    
    // å‰µå»ºä¸€å€‹æª”æ¡ˆä¾†å„²å­˜éœ€è¦ AI æ­¸ç´çš„å…§å®¹
    let mut ai_tasks = Vec::new();
    
    for code in codes {
        let stock = database.get(&code).unwrap().clone();
        
        if stock.website.is_some() {
            continue;
        }
        
        processed += 1;
        println!("\n[{}/{}] è™•ç†: {} - {}", processed, needs_update_count, stock.code, stock.name);
        
        // 1. æœå°‹å…¬å¸å®˜ç¶²
        let website = match search_company_website(&client, &stock.code, &stock.name).await {
            Ok(url) => {
                println!("  âœ“ æ‰¾åˆ°å®˜ç¶²: {}", url);
                Some(url)
            }
            Err(e) => {
                println!("  âœ— æœå°‹å®˜ç¶²å¤±æ•—: {}", e);
                None
            }
        };
        
        // 2. å¦‚æœæ‰¾åˆ°å®˜ç¶²,æŠ“å–å…§å®¹
        if let Some(ref url) = website {
            sleep(Duration::from_millis(500)).await;
            
            match fetch_website_content(&client, url).await {
                Ok(content) => {
                    println!("  âœ“ æŠ“å–å®˜ç¶²å…§å®¹æˆåŠŸ ({} å­—å…ƒ)", content.len());
                    
                    // å„²å­˜åˆ°å¾…è™•ç†åˆ—è¡¨
                    ai_tasks.push(AITask {
                        code: stock.code.clone(),
                        name: stock.name.clone(),
                        website: url.clone(),
                        content: content.clone(),
                    });
                }
                Err(e) => {
                    println!("  âœ— æŠ“å–å®˜ç¶²å…§å®¹å¤±æ•—: {}", e);
                }
            }
        }
        
        // 3. æ›´æ–°è³‡æ–™åº«
        if let Some(stock_mut) = database.get_mut(&code) {
            stock_mut.website = website;
            stock_mut.last_updated = Some(Local::now().format("%Y-%m-%d %H:%M:%S").to_string());
        }
        
        // æ¯è™•ç† 10 å®¶å…¬å¸å°±å„²å­˜ä¸€æ¬¡
        if processed % 10 == 0 {
            println!("\nğŸ’¾ å„²å­˜é€²åº¦...");
            save_stock_database(output_file, &database)?;
            save_ai_tasks("ai_tasks.json", &ai_tasks)?;
        }
        
        // é¿å…è«‹æ±‚éå¿«
        sleep(Duration::from_secs(2)).await;
    }
    
    // æœ€çµ‚å„²å­˜
    println!("\nğŸ’¾ å„²å­˜æœ€çµ‚çµæœ...");
    save_stock_database(output_file, &database)?;
    save_ai_tasks("ai_tasks.json", &ai_tasks)?;
    
    println!("\nâœ… å®Œæˆ!");
    println!("ğŸ“„ å®˜ç¶²è³‡æ–™å·²å„²å­˜è‡³: {}", output_file);
    println!("ğŸ“‹ å¾… AI æ­¸ç´çš„å…§å®¹å·²å„²å­˜è‡³: ai_tasks.json");
    println!("\nğŸ’¡ ä¸‹ä¸€æ­¥: ä½¿ç”¨ Kiro æ‰¹æ¬¡è™•ç† ai_tasks.json ä¸­çš„å…§å®¹");
    
    Ok(())
}

#[derive(Debug, serde::Serialize, serde::Deserialize)]
struct AITask {
    code: String,
    name: String,
    website: String,
    content: String,
}

fn save_ai_tasks(filename: &str, tasks: &[AITask]) -> Result<(), Box<dyn Error>> {
    let json = serde_json::to_string_pretty(tasks)?;
    std::fs::write(filename, json)?;
    Ok(())
}

async fn search_company_website(
    client: &reqwest::Client,
    code: &str,
    name: &str,
) -> Result<String, Box<dyn Error>> {
    let query = format!("{} {} å…¬å¸ å®˜ç¶²", code, name);
    let search_url = format!(
        "https://www.google.com/search?q={}",
        urlencoding::encode(&query)
    );
    
    let response = client.get(&search_url).send().await?;
    let html = response.text().await?;
    let document = Html::parse_document(&html);
    
    let link_selector = Selector::parse("a").unwrap();
    let url_regex = Regex::new(r#"https?://[^\s&"'<>]+"#).unwrap();
    
    for element in document.select(&link_selector) {
        if let Some(href) = element.value().attr("href") {
            if let Some(url_match) = url_regex.find(href) {
                let url = url_match.as_str();
                
                if !url.contains("google.com") 
                    && !url.contains("youtube.com")
                    && !url.contains("facebook.com")
                    && !url.contains("wikipedia.org")
                    && !url.contains("yahoo.com")
                    && !url.contains("goodinfo.tw")
                    && (url.contains(".com.tw") || url.contains(".tw") || url.contains(".com"))
                {
                    return Ok(url.to_string());
                }
            }
        }
    }
    
    Err("æ‰¾ä¸åˆ°æœ‰æ•ˆçš„å…¬å¸å®˜ç¶²".into())
}

async fn fetch_website_content(
    client: &reqwest::Client,
    url: &str,
) -> Result<String, Box<dyn Error>> {
    let response = client.get(url).send().await?;
    let html = response.text().await?;
    let document = Html::parse_document(&html);
    
    let body_selector = Selector::parse("body").unwrap();
    let mut content = String::new();
    
    if let Some(body) = document.select(&body_selector).next() {
        content = body.text().collect::<Vec<_>>().join(" ");
    }
    
    content = content
        .split_whitespace()
        .collect::<Vec<_>>()
        .join(" ");
    
    // é™åˆ¶åœ¨ 2000 å­—å…ƒä»¥å…§
    if content.len() > 2000 {
        content.truncate(2000);
    }
    
    Ok(content)
}
