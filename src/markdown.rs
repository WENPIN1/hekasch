use chrono::{DateTime, Duration, Local, NaiveDate};
use regex::Regex;
use scraper::{Html, Selector};
use std::error::Error;
use tokio::time::sleep;
use std::time::Duration as StdDuration;
use std::path::Path;
use std::fs;
use log::{debug, info};

#[derive(Debug)]
struct NewsItem {
    title: String,
    url: String,
    date: String,
    content: String,
    is_free: bool,
    detail_title: String,
    media: String,
    detail_date: String,
    views: String,
    detail_content: String,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    // åˆå§‹åŒ– logger
    env_logger::init();
    
    // é…ç½®ï¼šè¨­å®šè¦æŠ“å–çš„æ™‚é–“ç¯„åœï¼ˆå°æ™‚ï¼‰
    const HOURS_RANGE: i64 = 96; // æ¸¬è©¦æ™‚ä½¿ç”¨ 1 å°æ™‚ï¼Œæ­£å¼ä½¿ç”¨æ™‚æ”¹ç‚º 96
    
    info!("æ­£åœ¨æŠ“å– IEK ç”¢æ¥­æƒ…å ±ç¶²æœ€è¿‘ {} å°æ™‚å…§çš„æ–°è...\n", HOURS_RANGE);

    let client = reqwest::Client::builder()
        .user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        .build()?;

    let now = Local::now();
    let cutoff_time = now - Duration::hours(HOURS_RANGE);
    let mut all_news_items = Vec::new();
    let mut page_index = 1;
    let mut should_continue = true;
    
    // æª¢æŸ¥è¼¸å‡ºæª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨ï¼Œä¸¦è®€å–ç¬¬ä¸€ç­† URL
    let output_filename = format!("iek_news_{}.md", now.format("%Y-%m-%d"));
    let existing_first_url = get_first_url_from_markdown(&output_filename);

    while should_continue {
        let url = if page_index == 1 {
            "https://ieknet.iek.org.tw/ieknews/Default.aspx".to_string()
        } else {
            format!("https://ieknet.iek.org.tw/ieknews/Default.aspx?currentPageIndex={}", page_index)
        };

        debug!("æ­£åœ¨æŠ“å–ç¬¬ {} é ...", page_index);
        
        let response = client.get(&url).send().await?;
        let html_content = response.text().await?;
        
        let (news_items, has_old_news) = parse_news_with_check(&html_content, &cutoff_time)?;
        
        // å¦‚æœæ˜¯ç¬¬ä¸€é ä¸”æœ‰æ–°èï¼Œæª¢æŸ¥ç¬¬ä¸€ç­† URL æ˜¯å¦å·²å­˜åœ¨
        if page_index == 1 && !news_items.is_empty() {
            if let Some(ref existing_url) = existing_first_url {
                if news_items[0].url == *existing_url {
                    info!("âœ“ æ–°èè³‡æ–™å·²ä¸‹è¼‰ï¼ˆç¬¬ä¸€ç­† URL ç›¸åŒï¼‰ï¼ŒçµæŸæŠ“å–");
                    return Ok(());
                }
            }
        }
        
        let valid_count = news_items.len();
        all_news_items.extend(news_items);
        
        debug!("  æ‰¾åˆ° {} å‰‡ {} å°æ™‚å…§çš„æ–°è", valid_count, HOURS_RANGE);
        
        // å¦‚æœé€™ä¸€é æœ‰è¶…å‡ºæŒ‡å®šæ™‚é–“çš„æ–°èï¼Œåœæ­¢æŠ“å–
        if has_old_news {
            debug!("  ç™¼ç¾è¶…å‡º {} å°æ™‚çš„æ–°èï¼Œåœæ­¢æŠ“å–\n", HOURS_RANGE);
            should_continue = false;
        } else if valid_count == 0 {
            debug!("  æœ¬é ç„¡æœ‰æ•ˆæ–°èï¼Œåœæ­¢æŠ“å–\n");
            should_continue = false;
        } else {
            page_index += 1;
        }
    }

    // è¼¸å‡ºçµæœåˆ°çµ‚ç«¯
    if all_news_items.is_empty() {
        info!("æœªæ‰¾åˆ°æœ€è¿‘ {} å°æ™‚å…§çš„æ–°è", HOURS_RANGE);
    } else {
        let total_count = all_news_items.len();
        info!("ç¸½å…±æ‰¾åˆ° {} å‰‡æœ€è¿‘ {} å°æ™‚å…§çš„æ–°è\n", total_count, HOURS_RANGE);
        
        // æŠ“å–æ¯å‰‡æ–°èçš„è©³ç´°å…§å®¹
        info!("æ­£åœ¨æŠ“å–æ–°èè©³ç´°å…§å®¹...\n");
        let mut i = 0;
        while i < total_count {
            let item = &mut all_news_items[i];
            debug!("  æŠ“å–ç¬¬ {}/{} å‰‡æ–°èè©³ç´°å…§å®¹...", i + 1, total_count);
            match fetch_news_detail(&client, &item.url).await {
                Ok((detail_title, media, detail_date, views, detail_content, from_cache)) => {
                    item.detail_title = detail_title;
                    item.media = media;
                    item.detail_date = detail_date;
                    item.views = views;
                    item.detail_content = detail_content;
                    
                    if from_cache {
                        debug!(" âœ“ (å¿«å–)");
                    } else {
                        debug!(" âœ“");
                        // åªæœ‰å¾ç¶²è·¯æŠ“å–æ™‚æ‰æš«åœ 100 æ¯«ç§’
                        sleep(StdDuration::from_millis(100)).await;
                    }
                }
                Err(e) => {
                    debug!(" âœ— (éŒ¯èª¤: {})", e);
                }
            }
            
            // æ¯ 10 å‰‡æ–°èå­˜æª”ä¸€æ¬¡
            if (i + 1) % 10 == 0 || (i + 1) == total_count {
                debug!("  ğŸ’¾ å„²å­˜é€²åº¦ ({}/{})...", i + 1, total_count);
                if let Err(e) = generate_markdown_file(&all_news_items, &now) {
                    debug!("  âš ï¸  å­˜æª”å¤±æ•—: {}", e);
                }
            }
            
            i += 1;
        }
        debug!("");
        
        for (i, item) in all_news_items.iter().enumerate() {
            debug!("ã€æ–°è {}ã€‘", i + 1);
            debug!("æ¨™é¡Œ: {}", item.title);
            debug!("é€£çµ: {}", item.url);
            debug!("æ—¥æœŸ: {}", item.date);
            debug!("é¡å‹: {}", if item.is_free { "å…è²»" } else { "ä»˜è²»" });
            if !item.content.is_empty() {
                debug!("æ‘˜è¦: {}", item.content);
            }
            debug!("{}", "-".repeat(80));
        }
    }

    // ç”Ÿæˆ Markdown æª”æ¡ˆ
    generate_markdown_file(&all_news_items, &now)?;

    Ok(())
}

fn parse_news_with_check(html: &str, cutoff_time: &DateTime<Local>) -> Result<(Vec<NewsItem>, bool), Box<dyn Error>> {
    let document = Html::parse_document(html);
    let mut news_items = Vec::new();
    let mut has_old_news = false;
    let date_re = Regex::new(r"(\d{4}/\d{1,2}/\d{1,2})")?;

    // é¸æ“‡æ‰€æœ‰ <div class="listItem row no-gutters"> å…ƒç´ 
    let list_item_selector = Selector::parse("div.listItem.row.no-gutters").unwrap();
    let article_selector = Selector::parse("article.col-md.listText").unwrap();
    let link_selector = Selector::parse("h2 a").unwrap();
    let date_selector = Selector::parse("li.date").unwrap();
    
    for list_item in document.select(&list_item_selector) {
        // åœ¨ listItem å…§å°‹æ‰¾ article
        if let Some(article) = list_item.select(&article_selector).next() {
            // æå–é€£çµå’Œæ¨™é¡Œ
            if let Some(link) = article.select(&link_selector).next() {
                let url = link
                    .value()
                    .attr("href")
                    .unwrap_or("")
                    .replace("&amp;", "&");
                
                let title = link
                    .value()
                    .attr("title")
                    .unwrap_or("")
                    .to_string();
                
                if title.is_empty() {
                    continue;
                }

                // æå–æ—¥æœŸ
                let mut date_str = String::new();
                for date_elem in article.select(&date_selector) {
                    let date_text: String = date_elem.text().collect();
                    if let Some(date_match) = date_re.find(&date_text) {
                        date_str = date_match.as_str().to_string();
                        break;
                    }
                }

                if date_str.is_empty() {
                    continue;
                }

                // æª¢æŸ¥æ—¥æœŸæ˜¯å¦åœ¨æŒ‡å®šæ™‚é–“å…§
                if !is_within_hours(&date_str, cutoff_time) {
                    has_old_news = true;
                    continue;
                }

                // æå–å…¶ä»–è³‡è¨Š
                let article_text: String = article.text().collect();
                let is_free = article_text.contains("Free") || article_text.contains("å…è²»");
                
                // æå–æ‘˜è¦
                let content = article_text
                    .lines()
                    .find(|line| {
                        let trimmed = line.trim();
                        trimmed.len() > 20 
                            && !trimmed.contains(&title)
                            && !date_re.is_match(trimmed)
                    })
                    .unwrap_or("")
                    .trim()
                    .to_string();

                // ç¢ºä¿ URL æ˜¯å®Œæ•´çš„
                let full_url = if url.starts_with("http") {
                    url
                } else if url.starts_with("/") {
                    format!("https://ieknet.iek.org.tw{}", url)
                } else {
                    format!("https://ieknet.iek.org.tw/{}", url)
                };

                news_items.push(NewsItem {
                    title,
                    url: full_url,
                    date: date_str,
                    content,
                    is_free,
                    detail_title: String::new(),
                    media: String::new(),
                    detail_date: String::new(),
                    views: String::new(),
                    detail_content: String::new(),
                });
            }
        }
    }

    Ok((news_items, has_old_news))
}

fn is_within_hours(date_str: &str, cutoff_time: &DateTime<Local>) -> bool {
    let date_str = date_str.replace("/", "-");
    
    if let Ok(naive_date) = NaiveDate::parse_from_str(&date_str, "%Y-%m-%d") {
        if let Some(date_time) = naive_date
            .and_hms_opt(0, 0, 0)
            .and_then(|dt| dt.and_local_timezone(Local).single())
        {
            return date_time >= *cutoff_time;
        }
    }

    false
}

async fn fetch_news_detail(client: &reqwest::Client, url: &str) -> Result<(String, String, String, String, String, bool), Box<dyn std::error::Error>> {
    // å¾ URL ä¸­æå– nsl_id
    let nsl_id = extract_nsl_id(url);
    
    // æª¢æŸ¥å¿«å–
    if let Some(ref id) = nsl_id {
        let cache_path = format!("news_cache/{}.html", id);
        if Path::new(&cache_path).exists() {
            let metadata = fs::metadata(&cache_path)?;
            if metadata.len() > 0 {
                // å¾å¿«å–è®€å–
                let cached_html = fs::read_to_string(&cache_path)?;
                let (detail_title, media, detail_date, views, detail_content) = parse_cached_html(&cached_html)?;
                return Ok((detail_title, media, detail_date, views, detail_content, true)); // true è¡¨ç¤ºä½¿ç”¨å¿«å–
            }
        }
    }
    
    let response = client.get(url).send().await?;
    let html_content = response.text().await?;
    let document = Html::parse_document(&html_content);

    // æå–æ¨™é¡Œ
    let title_selector = Selector::parse("div.headingCh.mt-2#title").unwrap();
    let detail_title = document
        .select(&title_selector)
        .next()
        .map(|elem| elem.inner_html().trim().to_string())
        .unwrap_or_default();

    // æå–åª’é«”/è¨˜è€…
    let media_selector = Selector::parse("li.list-inline-item.mr-4[title='åª’é«”ã€è¨˜è€…']").unwrap();
    let media = document
        .select(&media_selector)
        .next()
        .map(|elem| elem.text().collect::<String>().trim().to_string())
        .unwrap_or_default();

    // æå–æ—¥æœŸ
    let date_selector = Selector::parse("li.list-inline-item.mr-3[title='æ—¥æœŸ']").unwrap();
    let detail_date = document
        .select(&date_selector)
        .next()
        .map(|elem| elem.text().collect::<String>().trim().to_string())
        .unwrap_or_default();

    // æå–ç€è¦½æ•¸
    let views_selector = Selector::parse("li.list-inline-item[title='ç€è¦½æ•¸']").unwrap();
    let views = document
        .select(&views_selector)
        .next()
        .map(|elem| elem.text().collect::<String>().trim().to_string())
        .unwrap_or_default();

    // æå–è©³ç´°å…§å®¹
    let content_selector = Selector::parse("div.detailContent").unwrap();
    let detail_content = document
        .select(&content_selector)
        .next()
        .map(|elem| elem.inner_html().trim().to_string())
        .unwrap_or_default();

    // å„²å­˜åˆ°å¿«å–
    if let Some(ref id) = nsl_id {
        fs::create_dir_all("news_cache")?;
        let cache_path = format!("news_cache/{}.html", id);
        
        // çµ„åˆå®Œæ•´çš„ HTML fragment
        let full_fragment = format!(
            r#"<div class="cached-news">
<div class="headingCh mt-2" id="title">{}</div>
<ul class="list-inline">
<li class="list-inline-item mr-4" title="åª’é«”ã€è¨˜è€…">{}</li>
<li class="list-inline-item mr-3" title="æ—¥æœŸ">{}</li>
<li class="list-inline-item" title="ç€è¦½æ•¸">{}</li>
</ul>
<div class="detailContent">{}</div>
</div>"#,
            detail_title, media, detail_date, views, detail_content
        );
        
        fs::write(&cache_path, &full_fragment)?;
    }

    Ok((detail_title, media, detail_date, views, detail_content, false)) // false è¡¨ç¤ºå¾ç¶²è·¯æŠ“å–
}

fn extract_nsl_id(url: &str) -> Option<String> {
    // å¾ URL ä¸­æå– nsl_id åƒæ•¸
    // ä¾‹å¦‚: https://ieknet.iek.org.tw/ieknews/news_more.aspx?actiontype=ieknews&indu_idno=0&nsl_id=2d6e228903aa4876b147cb71eb3ff878
    if let Some(query_start) = url.find("nsl_id=") {
        let id_start = query_start + 7; // "nsl_id=" çš„é•·åº¦
        let id_part = &url[id_start..];
        // æ‰¾åˆ°ä¸‹ä¸€å€‹ & æˆ–å­—ä¸²çµå°¾
        let id_end = id_part.find('&').unwrap_or(id_part.len());
        return Some(id_part[..id_end].to_string());
    }
    None
}

fn parse_cached_html(html: &str) -> Result<(String, String, String, String, String), Box<dyn std::error::Error>> {
    let document = Html::parse_document(html);
    
    let title_selector = Selector::parse("div.headingCh.mt-2#title").unwrap();
    let detail_title = document
        .select(&title_selector)
        .next()
        .map(|elem| elem.inner_html().trim().to_string())
        .unwrap_or_default();

    let media_selector = Selector::parse("li.list-inline-item.mr-4[title='åª’é«”ã€è¨˜è€…']").unwrap();
    let media = document
        .select(&media_selector)
        .next()
        .map(|elem| elem.text().collect::<String>().trim().to_string())
        .unwrap_or_default();

    let date_selector = Selector::parse("li.list-inline-item.mr-3[title='æ—¥æœŸ']").unwrap();
    let detail_date = document
        .select(&date_selector)
        .next()
        .map(|elem| elem.text().collect::<String>().trim().to_string())
        .unwrap_or_default();

    let views_selector = Selector::parse("li.list-inline-item[title='ç€è¦½æ•¸']").unwrap();
    let views = document
        .select(&views_selector)
        .next()
        .map(|elem| elem.text().collect::<String>().trim().to_string())
        .unwrap_or_default();

    let content_selector = Selector::parse("div.detailContent").unwrap();
    let detail_content = document
        .select(&content_selector)
        .next()
        .map(|elem| elem.inner_html().trim().to_string())
        .unwrap_or_default();

    Ok((detail_title, media, detail_date, views, detail_content))
}

fn get_first_url_from_markdown(filename: &str) -> Option<String> {
    // å¦‚æœæª”æ¡ˆä¸å­˜åœ¨ï¼Œè¿”å› None
    if !Path::new(filename).exists() {
        return None;
    }
    
    // è®€å–æª”æ¡ˆå…§å®¹
    let content = match fs::read_to_string(filename) {
        Ok(c) => c,
        Err(_) => return None,
    };
    
    // ä½¿ç”¨æ­£å‰‡è¡¨é”å¼å°‹æ‰¾ç¬¬ä¸€å€‹æ–°èé …ç›®çš„ URL
    // æ ¼å¼: ## 1. [æ¨™é¡Œ](URL)
    let re = Regex::new(r"##\s+1\.\s+\[.+?\]\((.+?)\)").unwrap();
    
    if let Some(captures) = re.captures(&content) {
        if let Some(url_match) = captures.get(1) {
            return Some(url_match.as_str().to_string());
        }
    }
    
    None
}

fn generate_markdown_file(news_items: &[NewsItem], now: &DateTime<Local>) -> Result<(), Box<dyn Error>> {
    let filename = format!("iek_news_{}.md", now.format("%Y-%m-%d"));
    
    let mut markdown = String::new();
    
    // æ¨™é¡Œ
    markdown.push_str("# IEK ç”¢æ¥­æƒ…å ±ç¶² - æœ€è¿‘ 96 å°æ™‚æ–°è\n\n");
    
    // å…ƒè³‡è¨Š
    markdown.push_str(&format!("**æŠ“å–æ™‚é–“**: {}\n\n", now.format("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")));
    markdown.push_str(&format!("**æ–°èæ•¸é‡**: {} å‰‡\n\n", news_items.len()));
    markdown.push_str("---\n\n");
    
    // æ–°èé …ç›®
    for (i, item) in news_items.iter().enumerate() {
        // æ¨™é¡Œèˆ‡é€£çµ
        let title = if !item.detail_title.is_empty() { &item.detail_title } else { &item.title };
        markdown.push_str(&format!("## {}. [{}]({})\n\n", i + 1, title, item.url));
        
        // è³‡è¨Šåˆ—
        let mut info_parts = vec![format!("ğŸ“… {}", item.date)];
        
        // åªåœ¨å…è²»æ–°èæ™‚é¡¯ç¤º badge
        if item.is_free {
            info_parts.push("ğŸ†“ **å…è²»**".to_string());
        }
        
        // é¡¯ç¤ºåª’é«”ã€æ—¥æœŸã€ç€è¦½æ•¸
        if !item.media.is_empty() {
            info_parts.push(format!("ğŸ“° {}", item.media));
        }
        if !item.detail_date.is_empty() {
            info_parts.push(format!("ğŸ•’ {}", item.detail_date));
        }
        if !item.views.is_empty() {
            info_parts.push(format!("ğŸ‘ {}", item.views));
        }
        
        markdown.push_str(&info_parts.join(" | "));
        markdown.push_str("\n\n");
        
        // é¡¯ç¤ºè©³ç´°å…§å®¹
        if !item.detail_content.is_empty() {
            markdown.push_str(&convert_html_to_markdown(&item.detail_content));
        } else if !item.content.is_empty() {
            markdown.push_str(&convert_html_to_markdown(&item.content));
        }
        
        markdown.push_str("\n\n---\n\n");
    }
    
    // é å°¾
    markdown.push_str("**è³‡æ–™ä¾†æº**: [IEK ç”¢æ¥­æƒ…å ±ç¶²](https://ieknet.iek.org.tw/ieknews/Default.aspx)\n");
    
    std::fs::write(&filename, markdown)?;
    info!("\nâœ… å·²å°‡çµæœå„²å­˜è‡³: {}", filename);
    
    Ok(())
}

// ç°¡å–®çš„ HTML è½‰ Markdown å‡½æ•¸
fn convert_html_to_markdown(html: &str) -> String {
    let mut text = html.to_string();
    
    // ç§»é™¤ HTML æ¨™ç±¤ä½†ä¿ç•™å…§å®¹
    // è™•ç†æ®µè½
    text = text.replace("<p>", "\n").replace("</p>", "\n");
    text = text.replace("<br>", "\n").replace("<br/>", "\n").replace("<br />", "\n");
    
    // è™•ç†æ¨™é¡Œ
    text = text.replace("<h1>", "\n### ").replace("</h1>", "\n");
    text = text.replace("<h2>", "\n### ").replace("</h2>", "\n");
    text = text.replace("<h3>", "\n#### ").replace("</h3>", "\n");
    text = text.replace("<h4>", "\n#### ").replace("</h4>", "\n");
    
    // è™•ç†ç²—é«”å’Œæ–œé«”
    text = text.replace("<strong>", "**").replace("</strong>", "**");
    text = text.replace("<b>", "**").replace("</b>", "**");
    text = text.replace("<em>", "*").replace("</em>", "*");
    text = text.replace("<i>", "*").replace("</i>", "*");
    
    // è™•ç†åˆ—è¡¨
    text = text.replace("<ul>", "\n").replace("</ul>", "\n");
    text = text.replace("<ol>", "\n").replace("</ol>", "\n");
    text = text.replace("<li>", "- ").replace("</li>", "\n");
    
    // è™•ç†é€£çµ - ç°¡å–®è™•ç†ï¼Œä¿ç•™ URL
    // æ›´è¤‡é›œçš„è™•ç†éœ€è¦æ­£å‰‡è¡¨é”å¼
    text = text.replace("<a ", "\n[").replace("</a>", "]");
    
    // è™•ç† div å’Œ span
    text = text.replace("<div>", "\n").replace("</div>", "\n");
    text = text.replace("<span>", "").replace("</span>", "");
    
    // ç§»é™¤å…¶ä»–å¸¸è¦‹æ¨™ç±¤
    let tags_to_remove = vec![
        "<table>", "</table>", "<tr>", "</tr>", "<td>", "</td>", "<th>", "</th>",
        "<thead>", "</thead>", "<tbody>", "</tbody>",
        "<img>", "</img>", "<figure>", "</figure>",
    ];
    for tag in tags_to_remove {
        text = text.replace(tag, " ");
    }
    
    // æ¸…ç†å¤šé¤˜çš„ç©ºç™½è¡Œ
    while text.contains("\n\n\n") {
        text = text.replace("\n\n\n", "\n\n");
    }
    
    text.trim().to_string()
}
